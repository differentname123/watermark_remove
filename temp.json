有没有办法进一步的优化inpaint_batch和inpaint的性能，给我优化后的完整代码：
import os
import torch
import numpy as np
from PIL import Image
from simple_lama_inpainting.utils.util import prepare_img_and_mask, download_model

LAMA_MODEL_URL = os.environ.get(
    "LAMA_MODEL_URL",
    "https://github.com/enesmsahin/simple-lama-inpainting/releases/download/v0.1.0/big-lama.pt",
)


class SimpleLama:
    def __init__(
        self,
        device: torch.device = torch.device("cuda" if torch.cuda.is_available() else "cpu"),
    ) -> None:
        if os.environ.get("LAMA_MODEL"):
            model_path = os.environ.get("LAMA_MODEL")
            if not os.path.exists(model_path):
                raise FileNotFoundError(f"lama torchscript model not found: {model_path}")
        else:
            model_path = download_model(LAMA_MODEL_URL)

        self.model = torch.jit.load(model_path, map_location=device)
        self.model.eval()
        self.model.to(device)
        self.device = device
        print(f"Model loaded to {self.device}.")


    def __call__(self, image: Image.Image | np.ndarray, mask: Image.Image | np.ndarray):
        # 单图片预处理
        image, mask = prepare_img_and_mask(image, mask, self.device)
        with torch.inference_mode():
            inpainted = self.model(image, mask)
            # 取出第一个batch元素进行后处理
            cur_res = inpainted[0].permute(1, 2, 0).detach().cpu().numpy()
            cur_res = np.clip(cur_res * 255, 0, 255).astype(np.uint8)
            cur_res = Image.fromarray(cur_res)
            return cur_res

    def inpaint(self, image: Image.Image | np.ndarray, mask: Image.Image | np.ndarray):
        """
        单图片修复接口，与 __call__ 方法效果一致。
        """
        return self.__call__(image, mask)

    def inpaint_batch(self, images: list[Image.Image | np.ndarray], masks: list[Image.Image | np.ndarray]):
        """
        批处理接口：
        1. 对每个 image 和 mask 使用 prepare_img_and_mask 进行预处理（假定返回的 tensor 均为形状 [1, C, H, W]）。
        2. 通过 torch.cat 拼接成一个批次张量，然后传入模型。
        3. 将模型输出的每个修复结果转换为 PIL Image，存储在列表中返回。
        """
        prepped_images = []
        prepped_masks = []
        for image, mask in zip(images, masks):
            img_tensor, mask_tensor = prepare_img_and_mask(image, mask, self.device)
            prepped_images.append(img_tensor)
            prepped_masks.append(mask_tensor)

        # 将单张图片的 batch 维度 (1, C, H, W) 拼接成 (N, C, H, W)
        images_tensor = torch.cat(prepped_images, dim=0)
        masks_tensor = torch.cat(prepped_masks, dim=0)

        with torch.inference_mode():
            inpainted_batch = self.model(images_tensor, masks_tensor)

        result_images = []
        # 遍历批次输出，并还原为 PIL Image
        for i in range(inpainted_batch.shape[0]):
            out_img = inpainted_batch[i].permute(1, 2, 0).detach().cpu().numpy()
            out_img = np.clip(out_img * 255, 0, 255).astype(np.uint8)
            result_images.append(Image.fromarray(out_img))
        return result_images